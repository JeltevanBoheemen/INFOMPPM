{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract search results with BeautifulSoup: PBS.org - part 03\n",
    "In our previous Notebook, we scraped only one page of the results. At the time of writing, there were 30 pages. By adding an extra for-loop to the code, we will traverse through all the pages. But before we do this, we will make the code dynamic so you can scrape multiple keywords from the site (if you want to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Retrieve how many pages there are\n",
    "This will vary per website, but luckily PBS.org displays the final page in the pagination overview. If you click on a link, you see the URL of your browser changes into something like:\n",
    "`https://www.pbs.org/newshour/search-results?q=%22artificial+intelligence%22&pnb=2` where `&pnb=2` is the current page. Again, this will change from site to site, but it is a welcome way to scrape for now.\n",
    "So now we need to know how many pages there are. Looking at the HTML code, the best strategy is to get the last item of the class `pagination__number`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# we need the %22 or \" to ensure that we get the combination artificial intelligence\n",
    "url = 'https://www.pbs.org/newshour/search-results?q=%22artificial%20intelligence%22'\n",
    "\n",
    "# get url\n",
    "page = requests.get(url)\n",
    "\n",
    "# transform to soup\n",
    "soup = BeautifulSoup(page.content, 'html')\n",
    "\n",
    "# search for pagination links\n",
    "pages = soup.find_all(class_='pagination__number')\n",
    "\n",
    "# [-1] selects last item in a list\n",
    "last_page = pages[-1].get_text()\n",
    "\n",
    "# convert to int\n",
    "number_of_pages = int(last_page)\n",
    "\n",
    "number_of_pages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create URL list\n",
    "Now we have our total number of pages we can create a nice url list. The `url_list` should be:\n",
    "`['https://www.pbs.org/newshour/search-results?q=%22artificial+intelligence%22&pnb=1',\n",
    " 'https://www.pbs.org/newshour/search-results?q=%22artificial+intelligence%22&pnb=2', ...\n",
    " 'https://www.pbs.org/newshour/search-results?q=%22artificial+intelligence%22&pnb=30'`\n",
    "This can be achieved by using a for-loop with a `range()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "\n",
    "def build_search_url(page):\n",
    "    url = 'https://www.pbs.org/newshour/search-results?'\n",
    "    params = {'q': '\"artifical intelligence\"', 'pnb': page}\n",
    "    encoded = urllib.parse.urlencode(params)\n",
    "    return url+encoded\n",
    "\n",
    "url_list = [build_search_url(n) for n in range(1, 51)]\n",
    "url_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Retrieve all the article URLs and save them in a list \n",
    "Use the `url_list` and collect all the URLs of the articles of each page. The `article_list` should only contain the URLs of the articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=1\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=2\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=3\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=4\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=5\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=6\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=7\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=8\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=9\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=10\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=11\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=12\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=13\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=14\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=15\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=16\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=17\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=18\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=19\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=20\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=21\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=22\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=23\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=24\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=25\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=26\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=27\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=28\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=29\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=30\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=31\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=32\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=33\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=34\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=35\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=36\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=37\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=38\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=39\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=40\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=41\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=42\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=43\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=44\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=45\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=46\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=47\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=48\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=49\n",
      "Retrieving https://www.pbs.org/newshour/search-results?q=%22artifical+intelligence%22&pnb=50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from itertools import chain\n",
    "\n",
    "def urls_from_search_page(soup):\n",
    "    results = soup.find_all(class_='search-result__title')\n",
    "    url_list = list(map(\n",
    "        lambda soup: soup.find('a')['href'],\n",
    "        results\n",
    "    ))\n",
    "    return url_list\n",
    "\n",
    "def soup_from_search_page(search_page_url):\n",
    "   print('Retrieving', search_page_url)\n",
    "   res = requests.get(search_page_url)\n",
    "   return BeautifulSoup(res.content)\n",
    "\n",
    "article_list = [\n",
    "   urls_from_search_page(soup_from_search_page(url))\n",
    "   for url in url_list\n",
    "]\n",
    "\n",
    "article_list = list(chain(*article_list))\n",
    "len(article_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Go through the list of articles and save the individual files.\n",
    "Look at the previous Notebooks in order to solve this part. Don't forget to use `article_list`. This can take some time to complete Â±15 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def save_article(article_url):\n",
    "    page = requests.get(article_url)\n",
    "    filename = article_url.replace('https://www.pbs.org/newshour/', '').replace('/', '-') + '.html'\n",
    "    destination = './data/' + filename\n",
    "    \n",
    "    with open(destination, 'w') as f:\n",
    "        f.write(page.text)\n",
    "    time.sleep(.5)\n",
    "\n",
    "for article in tqdm(article_list):\n",
    "    save_article(article)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37c10f95d263926787ebf1d430d11186fc6b9bac835b8518e0b5006ed24f0c36"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
